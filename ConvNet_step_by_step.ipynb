{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <!-- TITLE --> - TITLE : CONSTRUCTION D'UN RESEAU DE NEURONE CONVOLUTIF -\n",
    "<img  src=\"https://th.bing.com/th/id/R.0aaf9e85c30b4371246523d899ac485e?rik=w1qsqKXK6G7rpw&riu=http%3a%2f%2fwww.keil.com%2fpack%2fdoc%2fCMSIS_Dev%2fNN%2fhtml%2fCIFAR10_CNN.gif&ehk=%2fmLmJkB%2bQ%2fYXKrtUx7PwBTSMrqBS1OocIjU2v%2byUqSs%3d&risl=&pid=ImgRaw&r=0\"></img>\n",
    "\n",
    "#### <!-- AUTHOR --> - Author : __Dr. Amiehe-Essomba__ (c) 2023\n",
    "\n",
    "## Description du projet : \n",
    "Le reseau que nous allons mettre en place ressemblera à cellui de l'image, ou nous avons une volume en entrée \n",
    "(une image) de dimension (largeur, hauteur, profondeur) ou\n",
    "  - __largeur__ est la largeur de l'image \n",
    "  - __hauteur__ est la hauteur de l'image \n",
    "  - __profondeur__ est le nombre de canneaux de l'image (RBG) si ```profondeur = 3```\n",
    "\n",
    "Ce volume (imaage) est traité de la la magnière suivante :\n",
    "Nous avons une noyau de dimension (n, n, profondeur) appelé nouyau de convolution que nous allons appliqué  sur \n",
    "le volume d'entrée et obtenir un volume de sorti qui corespond à une image intermediaire nous pouvons ainsi\n",
    "appliquer plusieurs filtres de convolutions pour fragementer de façon plus significative le volume d'entré.\n",
    "\n",
    "Ceci voudrait tout simplement dire que  si nous avons une image de ```(32x32x3)```\n",
    "```python\n",
    "  - hauteur = 32\n",
    "  - largeur = 32\n",
    "  - profondeur = 3\n",
    "```\n",
    "avec un noyau de convolution de ```(3x3x3)```\n",
    "nous obtiendrons une surface de dimension (26x26) en utilisant 32 filtres de convolution, l'image intermediaire \n",
    "obtenue aura pour dimension (32x32x32) avec un ```padding p = 1``` pou conserver le volume d'entré. Nous verrons par la suite \\\n",
    "comment utiliser le __padding__ et le __stride__ pour manipuler l'image d'entrée.\n",
    "\n",
    "Sur l'image intermediare de dimension ```(32x32x32)``` nous appliquerons ensuite un autre filtre pour \n",
    "extraire les caractéristiques les pertinentes en appliquant un MaxPooling ou un AvgPooling ce qui \n",
    "à pour objectif de reduire non seulement la taille de l'image intermediare en gardant les caractéristiques\n",
    "les plus importante tout en convervant la nature d'entrée.\n",
    "\n",
    "Ceci voudrait dire que si nous avons un volume avant d'appliquer un filtre de pooling, après avoir appliquer ce dernier la sorti\n",
    "sera un également un volume cependant les dimensions de l'image seront resuites \n",
    "\n",
    "  - Notre image intermediare à pour dimension ```(32x32x32)``` avec un Maxpooling ayant pour filtre ```(2x2x32)```\n",
    "  nous obtiendrons une seconde image intermediare de dimension (16x16x10). nous verrons également comment fonction le __Pooling__.\n",
    "\n",
    "Ce procedé peut etre repété plusieur fois comme suite\n",
    "\n",
    "```python\n",
    "(32x32x3)      (3x3x3)  32 filtres   (2x2x32)         (3x3x32)  (50 filtre)  (2x2x32)\n",
    "[image] -----> (Noyau) ------------> (Pooling) ------>(Noyau) ------------> (Poling) ----> (8x8x32) \n",
    "                        (32x32)             (16x16x32)            (16x16) \n",
    "                          p=1                                       p=1\n",
    "```         \n",
    "\n",
    "Une fois le procédé d'extraction terminé nous povons applatire les données pour obtenir un vecteur colone avec pour dimension \\\n",
    "```Vec.dim() = (512, 1)``` qui sara utilisé pour  la predmière couche dense de neurone Full connected (FC)\n",
    "\n",
    "```python\n",
    "\n",
    "                    Cov1('RelU')                   Cov2('RelU',)                   (4x4x32)\n",
    "(28x28x3)      (3x3x3) 32 filtres (2x2x32)    (3x3x32) (32 filtre)   (2x2x32)      Vector         (200)          (classes)\n",
    "[image] -----> (Noyau) ---------> (Pooling)---->(Noyau) --------->  (Poling).....Flatten()--->FC1('ReLU')---->FC1('Softmax')\n",
    "                        (32x32)                            (16x16) \n",
    "                          p=1                                p=1\n",
    "```\n",
    "\n",
    "\n",
    "Comme le demontre le schema ci-dessus nous avons deux couches couche de convolutions et deux couches full connected.\n",
    "  - La première coche full conncted(FC1) utilise comme fonction d'activation __ReLU__ avec ``` 200 ``` neurones \n",
    "  - La première coche full conncted(FC1) utilise comme fonction d'activation __Sotfmax__ avec ``` n_classes ``` neurone \\\n",
    "    car il s'agit dans ce cas d'une classification multiple (chien, chat, oiseau, etc...)\n",
    "  - Les deux couches de convolutions utilisent également le function __ReLU__ comme fonction d'activation cependant avec un nombre \\\n",
    "    de paramètres différents\n",
    "\n",
    "\n",
    "## Objectives :\n",
    "  - Nosu allons construire un reseau de neurone convolutif (CNN) pour le traitement d'image \n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(X : np.ndarray, pad : int = 0):\n",
    "    \"\"\"\n",
    "    Noté que X à pour dimension (m, H, L, Nc)\n",
    "    M = nombres d'images\n",
    "    H = Hauteur de l'image \n",
    "    L = Largeur de l'image \n",
    "    Nc = profondeur de l'image \n",
    "\n",
    "    Padding constiste à faire du rembourage autour du volume d'entré(image) comme ci-dessous \n",
    "    \n",
    "        pad\n",
    "       ----->                    \n",
    "        +---+---+---+---+---+---+\n",
    "        | 0 | 0 | 0 | 0 | 0 | 0 | \n",
    "        +---+---+---+---+---+---+  \n",
    "        | 0 |               | 0 |\n",
    "        +---+               +---+\n",
    "        | 0 |  IMAGE HERE   | 0 |\n",
    "        +---+               +---+\n",
    "        | 0 |               | 0 |\n",
    "        +---+---+---+---+---+---+\n",
    "        | 0 | 0 | 0 | 0 | 0 | 0 | \n",
    "        +---+---+---+---+---+---+\n",
    "                            <-----\n",
    "                              pad\n",
    "\n",
    "    pour cela nous allons utilser la fonction numpy.pad() et nous allons ajouter des zeros autour de l'image \n",
    "    avec l'attribut constant_values de numpy.pad()\n",
    "\n",
    "    Chaque image de X faisant (H, L, Nc) dimension le padding ne s'applique que sur (H, L)\n",
    "    avec comme valeur : pad avec un mode constant\n",
    "\n",
    "    La matrix final X_pad aura pour dimension (m, H+2*pad, L+2*pad, Nc)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pad_width = (\n",
    "        (0,0),\n",
    "        (pad, pad),\n",
    "        (pad, pad),\n",
    "        (0, 0)\n",
    "    )\n",
    "    return np.pad(array = X, pad_width=pad_width ,constant_values=(0, 0), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_dim(kernel : tuple = (), X_shape : tuple =()):\n",
    "    error  = None\n",
    "    if len(kernel) == 2:\n",
    "        if kernel[0] == kernel[1]: \n",
    "            if type(kernel[0]) == type(int()):\n",
    "                if type(kernel[0]) == type(kernel[1]): pass\n",
    "                else: error = \"type( kernel[0] ) != type( kernel[1] )\"\n",
    "            else:\"type( kernel[0] ) != type( int() )\"\n",
    "        else: error = \"kernel[0] != kernel[1]\"\n",
    "    else: error = \"kerne.size() != 2\"\n",
    "    \n",
    "    error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv(X : np.ndarray, kernel_size : tuple = (), filters : int = 1, stride : int = 2, pad :int = 1):\n",
    "    \"\"\" \n",
    "    pour faire une convolution, comme expliqué plus haut nous avons besoin d'un noyau de \n",
    "    convolution de dimension (n, n, Nc)\n",
    "\n",
    "    ou Nc est la profondeur de la couche précédente \n",
    "    \"\"\"\n",
    "    # checking kernel size \n",
    "    error = kernel_dim(kernel=kernel_size)\n",
    "\n",
    "    if error is None:\n",
    "        # conversion du kernel en liste \n",
    "        kernel_size = list(kernel_size)\n",
    "        \n",
    "        # etape 1 : calcule la taille de l'image de sortie avec un paddind = pad et stride = stride\n",
    "        n_H             = (X.shape[1] + 2 * pad - kernel_size[0])//stride + 1\n",
    "        n_L             = (X.shape[2] + 2 * pad - kernel_size[1])//stride + 1 \n",
    "\n",
    "        \"\"\" \n",
    "                Before\n",
    "          +------------------+  \n",
    "          |                  |  \n",
    "          |                  |       after padding  and stride\n",
    "          |   image here     |----------------------------------+  \n",
    "          |                  |                                  |\n",
    "          |                  |                                  |   \n",
    "          |                  |                                  |\n",
    "          +------------------+                                  |\n",
    "                                                    +------------------------+\n",
    "                                                    |  +------------------+  |\n",
    "                                                    |  |                  |  |\n",
    "                                                    |  |                  |  |  \n",
    "                                                    |  |   image here     |  | \n",
    "                                                    |  |                  |  |\n",
    "                                                    |  |                  |  |\n",
    "                                                    |  |                  |  |\n",
    "                                                    |  +------------------+  |\n",
    "                                                    +------------------------+\n",
    "                                                                After\n",
    "        \"\"\"\n",
    "        # hyper paramètre \n",
    "        hp = {\n",
    "            \"pad\"       : pad,\n",
    "            \"stride\"    : stride\n",
    "        }\n",
    "\n",
    "        # étape 2 :  du padding \n",
    "        X_padding = padding(X=X, pad=pad)\n",
    "\n",
    "        # dimension de X\n",
    "        shape_X         = X_padding.shape \n",
    "    \n",
    "        # noyau final\n",
    "        kernel_size     = kernel_size + [shape_X[-1]]\n",
    "        #ajout du filtre dans ma matrice de convolution \n",
    "        kernel          = np.random.randn(filters, kernel_size[0], kernel_size[1], kernel_size[-1] )\n",
    "        kernel_shape    = kernel.shape\n",
    "        \n",
    "        # initialisation du biais\n",
    "        bias = np.random.randn(1,1,1, filters)\n",
    "        \n",
    "        # X_CONV\n",
    "        X_conv          = []\n",
    "\n",
    "        if n_H > 1: \n",
    "            if n_L > 1:\n",
    "                for i in range(shape_X[0]):\n",
    "                    \n",
    "                    # initialisation de la matrice de filtre\n",
    "                    X_img = []\n",
    "                    # boucle for en fonction du nombres de filtres appliqués\n",
    "                    for j in  range(filters):\n",
    "                        X_filters = []\n",
    "                        # 1er verification s\n",
    "                        # la taille du noyau est identique aux dimensions de l'image \n",
    "                        if kernel_shape[1] == shape_X[1]:\n",
    "                            S   = X_padding[i] * kernel[j] + bias\n",
    "                            SUM = S.sum().reshape((1,))[0] \n",
    "                            X_filters.append(SUM)\n",
    "                        # la taille du noyau est inférieur à la taille de l'image \n",
    "                        elif kernel_shape[1] < shape_X[1]:\n",
    "                            #size_H = shape_X[1] - kernel_shape[1] \n",
    "                            #size_L = shape_X[2] - kernel_shape[2]\n",
    "                            pas_H  = kernel_shape[1]\n",
    "                            pas_L  = kernel_shape[2]\n",
    "                                                \n",
    "                            # balayage du volume avec un pas de 1\n",
    "                            for k in range(n_H):\n",
    "                                for l in range(n_L):\n",
    "                                    S   = X_padding[i][ k * stride : pas_H + k * stride, l * stride : pas_L + l * stride , :]\n",
    "                                    S   = S * kernel[j] + bias[0, 0, 0, j]\n",
    "                                    SUM = S.sum()\n",
    "                                    X_filters.append(SUM)\n",
    "                            \n",
    "                        else: print('ERROR')\n",
    "\n",
    "                        X_filters = np.array(X_filters).reshape((n_H, n_L))\n",
    "                        X_img.append(X_filters)\n",
    "\n",
    "                    X_conv.append( np.array(X_img).reshape(n_H, n_L, filters) )\n",
    "                \n",
    "                cache = (X, kernel, bias, hp )\n",
    "                X_conv = np.array( X_conv)\n",
    "            \n",
    "                return X_conv , cache\n",
    "            else: return f\"Impossible d'appliquer le noyau de convolution {kernel_size}\" , None\n",
    "        else : return f\"Impossible d'appliquer le noyau de convolution {kernel_size}\" \n",
    "    \n",
    "    else: return error , None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pooling(X : np.ndarray, mode : str = 'MaxPooling', pool_size : tuple = (2, 2), params : dict = {}):\n",
    "    # dimension de X\n",
    "    shape = X.shape \n",
    "\n",
    "    # taille finale du filtre du pooling \n",
    "    # le pooling prend un volume en entré et retourne un volume c'est-a-dire \n",
    "    # si notre image est de dimension (n,n, c) ----> pool_size(2,2) ----->(n//2, n//x, c)\n",
    "    pool_size = list(pool_size) + [shape[-1]]\n",
    "    # stride \n",
    "    stride = params['stride']\n",
    "    # sample \n",
    "    sample = shape[0] \n",
    "    # channels\n",
    "    n_c = shape[-1]\n",
    "\n",
    "    # hauteur de l'image de sortie\n",
    "    n_H = (shape[1] - pool_size[0])// stride + 1\n",
    "    # largeur de l'image de sorties\n",
    "    n_L = (shape[2] - pool_size[1])// stride + 1\n",
    "\n",
    "    # initialisation de la matrice de pooling\n",
    "    X_pool = np.zeros((sample, n_H, n_L, n_c))\n",
    "\n",
    "    if n_H > 1:\n",
    "        if n_L > 1:\n",
    "            for i in range(sample):\n",
    "                for c in range(n_c) :\n",
    "                    for h in range(n_H):\n",
    "                        for w in range(n_L):\n",
    "                            x_pool = X[i][h * stride : h * stride + pool_size[0], w * stride : w * stride + pool_size[1], c]\n",
    "                            if   mode =='MaxPooling': X_pool[i, h, w, c] = np.max(x_pool)\n",
    "                            elif mode == 'AvgPooling' : X_pool[i, h, w, c] = np.mean(x_pool)\n",
    "                            else : X_pool[i, h, w, c] = np.nan \n",
    "\n",
    "                        else: pass \n",
    "                    else: pass \n",
    "                else: pass \n",
    "            else: pass \n",
    "            params['pool_shape'] = pool_size\n",
    "            cache = (X, params )\n",
    "            return X_pool, cache\n",
    "        else: return f\"Impossible d'appliquer le {mode} avec un noyau {pool_size}\" , None\n",
    "    else: return f\"Impossible d'appliquer le {mode} avec un noyau {pool_size}\" , None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_function(X : np.ndarray):\n",
    "    \"\"\"\n",
    "    X.dim() = [filters, filters]\n",
    "    \"\"\"\n",
    "\n",
    "    mask = X == X.max()\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_value(dz, shape, mode : str = 'AvgPooling'):\n",
    "    \"\"\"\n",
    "    Distributes the input value in the matrix of dimension shape\n",
    "    \n",
    "    Arguments:\n",
    "    dz -- input scalar\n",
    "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
    "    \n",
    "    Returns:\n",
    "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
    "    \"\"\"    \n",
    "\n",
    "    # (n_H, n_W) = None\n",
    "    (n_H, n_W) = shape\n",
    "    # Compute the value to distribute on the matrix \n",
    "    # average = None\n",
    "    \n",
    "    avg = dz / (n_H*n_W)\n",
    "    \n",
    "    # Create a matrix where every entry is the \"average\" value \n",
    "    X = np.zeros((n_H, n_W)) \n",
    "    X[:, :] = avg\n",
    "  \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_Backward(dZ : np.ndarray, cache : tuple = ()):\n",
    "\n",
    "    \"\"\"\"\n",
    "    dans cette section nous allons résoudre les equation de la rétropropagation (backward propagation)\n",
    "\n",
    "    * dX = dX + sum( sum( kernel * dZ_{H, L}  ) )\n",
    "    * dW = dW + sum( sum( X * dZ_{H, L} ) )\n",
    "    * db = dbias + sum( sum( dZ_{H, L} ) )\n",
    "    \n",
    "    ces trois equations permettent de reésoudre la rétropropagation \n",
    "    \n",
    "    \"\"\"\n",
    "    # données contenant les catéristique de l'image intermedaire, la forme du noyau, le bias et \n",
    "    # les hyper paramètres tels que le stride et le padding\n",
    "    (X, kernel, bias, params) = cache\n",
    "    # forme de l'image intermediare après la convolution\n",
    "    X_shape         = X.shape \n",
    "    # forme du noyau filnal obtenu lors de la convolution sur le volume X\n",
    "    kernel_shape    = kernel.shape\n",
    "    # forme de l'image intermediare après convolution\n",
    "    dZ_shape        = dZ.shape \n",
    "    # données du pad et du stride\n",
    "    pad             = params['pad']\n",
    "    stride          = params['stride']\n",
    "    # initialisation de nouveaux paramètres pour le rétro propagation\n",
    "    \"\"\" \n",
    "    dX = dX + sum_{h}[sum_{w} kernel[f, :, :, :] * dZ[m, h, w, filters]]\n",
    "    db = db + dZ[m, h, w, filters]\n",
    "    dW = dW + sum_{h}[sum_{w} x_slice * dZ[m, h, w, filters]]\n",
    "\n",
    "    \"\"\"\n",
    "    # la function cout du gradient en fonction de la sortie de la couche de convolution\n",
    "    dX              = np.zeros(X_shape)\n",
    "    # dérivée du kernel\n",
    "    dW              = np.zeros(kernel_shape)\n",
    "    # derivée du bias\n",
    "    dbias           = np.zeros((1,1,1,kernel_shape[-1]))\n",
    "    # hauteur du noyau\n",
    "    pas_H           = kernel_shape[1]\n",
    "    # largeur du noyau\n",
    "    pas_L           = kernel_shape[2]\n",
    "    # dimension de l'image intermediare apres la Conv\n",
    "    (m, n_H, n_L, filters) = dZ_shape \n",
    "\n",
    "    # padding sur le volue X avec une valeur constante et un pas = pad\n",
    "    X_padding       = padding(X=X, pad=pad)\n",
    "    # padding sur dX\n",
    "    dX_padding      = padding(X=dX, pad=pad)\n",
    "\n",
    "    for i in range(m):\n",
    "        dx_padding = dX_padding[i]\n",
    "        x_padding  = X_padding[i]\n",
    "        for f in range(filters):\n",
    "            for h in range(n_H):\n",
    "                for w in range(n_L):\n",
    "                    x_slice = x_padding[h *stride : h*stride+pas_H, w *stride : w*stride+pas_L, :]\n",
    "                    dx_padding[h *stride : h*stride+pas_H, w *stride : w*stride+pas_L, :] += kernel[f, :, :, :] * dZ[i, h, w, f]\n",
    "                    dW[f,:,:,:] += x_slice * dZ[i, h, w, f]\n",
    "                    dbias[:,:,:,f] += dZ[i, h, w, f]\n",
    "                else : pass \n",
    "            else: pass \n",
    "        else: pass \n",
    "        \n",
    "        dX_padding[i, :, :, :] = dx_padding\n",
    "    \n",
    "    return dX_padding[:, pad:-pad, pad:-pad, :], dW, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pooling_Backward(dZ : np.ndarray, cache : tuple = (), mode : str = \"MaxPooling\"):\n",
    "\n",
    "    \"\"\"\"\n",
    "    dans cette section nous allons résoudre les equation de la rétropropagation (backward propagation)\n",
    "\n",
    "    * dX = dX + sum( sum( kernel * dZ_{H, L}  ) )\n",
    "    * dW = dW + sum( sum( X * dZ_{H, L} ) )\n",
    "    * db = dbias + sum( sum( dZ_{H, L} ) )\n",
    "    \n",
    "    ces trois equations permettent de reésoudre la rétropropagation \n",
    "    \n",
    "    \"\"\"\n",
    "    # données contenant les catéristique de l'image intermedaire après le pooling\n",
    "    # les hyper paramètres tels que le stride et le filtre\n",
    "    (X, params) = cache\n",
    "    # forme de l'image après le pooling\n",
    "    X_shape         = X.shape \n",
    "    # forme de l'image intermediare après le pooling\n",
    "    dZ_shape        = dZ.shape \n",
    "    # données stride et du filtre\n",
    "    stride          = params['stride']\n",
    "    kernel_shape    = params['pool_shape']\n",
    "    # initialisation de nouveaux paramètres pour le rétro propagation\n",
    "    \n",
    "    dX              = np.zeros(X_shape)\n",
    "    # hauteur du noyau\n",
    "    pas_H           = kernel_shape[0]\n",
    "    # largeur du noyau\n",
    "    pas_L           = kernel_shape[1]\n",
    "    # filter\n",
    "    filter          = kernel_shape[-1]\n",
    "    # dimension de l'image intermediare apres la Conv\n",
    "    (m, n_H, n_L, filter) = dZ_shape \n",
    "    \n",
    "    for i in range(m):\n",
    "        x = X[i]\n",
    "        for f in range(filter):\n",
    "            for h in range(n_H):\n",
    "                for w in range(n_L):\n",
    "                    if mode == \"Maxploing\":\n",
    "                        x_prev  = x[h * stride:h * stride + pas_H , w * stride : w * stride + pas_L]\n",
    "                        mask    = mask_function(X=x_prev)\n",
    "                        dX[i, h * stride:h * stride + pas_H , w * stride : w * stride + pas_H, f] += mask * dZ[i, h, w, f]\n",
    "                    elif mode == 'AvgPooling':\n",
    "                        dx      = dZ[i, h, w, f]\n",
    "                        shape   = (filter, filter)            \n",
    "                        dX[i, h * stride:h * stride + pas_H , w * stride : w * stride + pas_H, f] += dist_value(dx, shape)\n",
    "                else : pass \n",
    "            else: pass \n",
    "        else: pass \n",
    "        \n",
    "    assert( dX.shape == X.shape)\n",
    "    \n",
    "    return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X           = np.random.randn(4, 3, 3, 2)\n",
    "X_padding   = padding(X, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_conv, cache_conv = Conv(X=X_padding, kernel_size=(4,4), filters=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dA, dW, db = Conv_Backward(dZ=X_conv, cache=cache_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'stride' : 1}\n",
    "X_pool, cache = Pooling(X_conv, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 4, 4, 2), (4, 3, 3, 2))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_conv.shape, X_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX = Pooling_Backward(dZ=X_pool, cache=cache, mode='AvgPooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image with padding')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(8,4))\n",
    "ax1, ax2  = axes.ravel()\n",
    "ax1.imshow(X[0, :, :, 0], cmap=\"gray\", interpolation='nearest')\n",
    "ax2.imshow(X_padding[0, :, :, 0], cmap=\"gray\", interpolation='nearest')\n",
    "\n",
    "ax1.set_xticks(())\n",
    "ax2.set_xticks(())\n",
    "ax1.set_yticks(())\n",
    "ax2.set_yticks(())\n",
    "\n",
    "ax1.set_title('True image')\n",
    "ax2.set_title('Image with padding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
